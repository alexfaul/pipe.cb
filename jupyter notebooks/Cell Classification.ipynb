{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in data - sub this out for dff\n",
    "\n",
    "root = 'Z://AFdata//2p2019//Sut1//190927_Sut1//'\n",
    "\n",
    "spks = np.load(os.path.join(root, 'unregisteredTIFFs//first2//suite2p//plane0//spks.npy'))\n",
    "stat = np.load(os.path.join(root, 'unregisteredTIFFs//first2//suite2p//plane0//stat.npy'), allow_pickle=True)\n",
    "fluor = np.load(os.path.join(root, 'unregisteredTIFFs//first2//suite2p//plane0//F.npy'), allow_pickle=True)\n",
    "npil = np.load(os.path.join(root, 'unregisteredTIFFs//first2//suite2p//plane0//Fneu.npy'), allow_pickle=True)\n",
    "iscell = np.load(os.path.join(root, 'unregisteredTIFFs//first2//suite2p//plane0//iscell.npy'))\n",
    "\n",
    "# these are the neurons' 2D coordinates\n",
    "ypos = [stat[n]['med'][0] for n in range(len(stat))] \n",
    "xpos = [stat[n]['med'][1] for n in range(len(stat))] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what alphas and shit to loop through?? \n",
    "\n",
    "##need to put in hyperparameter tuning\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def linear_regression(data, power, models_to_plot):\n",
    "    #initialize predictors:\n",
    "    predictors=['x']\n",
    "    if power>=2:\n",
    "        predictors.extend(['x_%d'%i for i in range(2,power+1)])\n",
    "    \n",
    "    #Fit the model\n",
    "    linreg = LinearRegression(normalize=True)\n",
    "    linreg.fit(data[predictors],data['y'])\n",
    "    y_pred = linreg.predict(data[predictors])\n",
    "    \n",
    "    #Check if a plot is to be made for the entered power\n",
    "    if power in models_to_plot:\n",
    "        plt.subplot(models_to_plot[power])\n",
    "        plt.tight_layout()\n",
    "        plt.plot(data['x'],y_pred)\n",
    "        plt.plot(data['x'],data['y'],'.')\n",
    "        plt.title('Plot for power: %d'%power)\n",
    "    \n",
    "    #Return the result in pre-defined format\n",
    "    rss = sum((y_pred-data['y'])**2)\n",
    "    ret = [rss]\n",
    "    ret.extend([linreg.intercept_])\n",
    "    ret.extend(linreg.coef_)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a dataframe to store the results:\n",
    "col = ['rss','intercept'] + ['coef_x_%d'%i for i in range(1,16)]\n",
    "ind = ['model_pow_%d'%i for i in range(1,16)]\n",
    "coef_matrix_simple = pd.DataFrame(index=ind, columns=col)\n",
    "\n",
    "#Define the powers for which a plot is required:\n",
    "models_to_plot = {1:231,3:232,6:233,9:234,12:235,15:236}\n",
    "\n",
    "#Iterate through all powers and assimilate results\n",
    "for i in range(1,16):\n",
    "    coef_matrix_simple.iloc[i-1,0:i+2] = linear_regression(data, power=i, models_to_plot=models_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## other way of doing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(max_iter = 10000, normalize = True)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(scale(X_train), y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.plot(alphas*2, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n",
    "lassocv.fit(X_train, y_train)\n",
    "\n",
    "lasso.set_params(alpha=lassocv.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, lasso.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lasso.coef_, index=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classical way to do this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-tests with bonferroni\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wilcoxon Sign-Rank test w/ bonferroni\n",
    "scipy.stats.wilcoxon(x, y=None, zero_method='wilcox', correction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We tested each bin (starting at cue onset), advancing in time until there were fewer than 10 trials \n",
    "#(of a given cue type) contributing to a given bin (with increasing time following cue onset, \n",
    "#a decreasing number of trials existed for which a lick response had not yet occurred). \n",
    "#For a cell to be considered visually responsive, we required 3 consecutive significant bins \n",
    "#(i.e.,  279 ms of significantly elevated activity above baseline, using the Wilcoxon Sign-Rank test described above). \n",
    "#Cells were deemed to be visually responsive on a given day if there was a significant increase in activity to at \n",
    "#least one visual cue. A cell’s ‘preferred’ visual cue on each day that the cell was driven was determined as the cue \n",
    "#evoking the largest mean response from 0-1 s post stimulus onset.\n",
    "\n",
    "#advance and test whether significant in 3 time bins\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
